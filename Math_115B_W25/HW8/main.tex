\documentclass{article}
\usepackage{amsmath} % For math equations
\usepackage{amsfonts} % For math fonts
\usepackage{amssymb} % For math symbols
\usepackage{float}
\usepackage{enumitem}
\usepackage{graphicx}
\setlist[enumerate,1]{label=\arabic*.}
\setlist[enumerate,2]{label=\alph*.,itemindent=2em}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\tr}{Tr}

\title{HW 8 - 115B}
\author{Asher Christian 006-150-286}
\date{ 03.11.25}

\begin{document}
    \maketitle
    \section{Exercise 1}
    \emph{
        Determine which of the following mappings given below are bilinear forms.
        Justify answers
        \begin{enumerate}[label = (\alph*)]
            \item Let $C[0,1]$ be the set of continuous real valued
                functions with domain $[0,1]$. For $f,g \in C[0,1]$, define
                $H(f,g) := \int_{0}^{1}f(x)g(x)dx$ 
            \item Let $V$ be a vector space over $k$, and let $J \in \mathbb{B}(V)$ be
                nonzero. Define  $H: V \times V \rightarrow k$ by the formula
                $H(v,w) = J(v,w)^2$ for all $v,w \in V$.
            \item The function $H: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ given by the formula
                $H(t_1,t_2) = t_1 + 2t_2$
            \item The function $D: \mathbb{R}^2 \times \mathbb{R}^2 \rightarrow \mathbb{R}$ given by the formula
                $D(\begin{pmatrix} a \\ b \end{pmatrix}, \begin{pmatrix} c \\ d \end{pmatrix} ) = ad-bc $
            \item Let $V$ be a real inner product space, and let $H : V \times V \rightarrow \mathbb{R}$ be the
                function $H(v,w) = \langle v, w \rangle$ for all $v,w \in V$.
            \item Let $V$ be a complex inner product space, and let $H : V \times V \rightarrow \mathbb{C}$ be
                the function $H(v,w) = \langle v, w \rangle$ for all $v,w \in V$
        \end{enumerate}
    }
    \begin{enumerate}[label= (\alph*)]
        \item for any $f,g,h \in C[0,1], a,b \in \mathbb{R}$
            \[
            \int_{0}^{1}(af +g)hdx = a\int_{0}^{1}fhdx + \int_{0}^{1}gdx = aH(f,h) + H(g,h)
            .\] 
            similarly
            \[
            \int_{0}^{1}fgdx = \int_{0}^{1}gfdx
            .\] 
            so H is bilinear.
        \item Let $v,w \in V$ be such that $J(v,w) = \alpha$ and $\alpha^2 \ne \alpha$ this is possible because if $J$ is nonzero there exist
            $v,w \in V$ such that $J(v,w) = \beta \ne 0$ and  $J(\beta^{-1}v +\beta^{-1}v,w) = 2\beta^{-1}J(v,w) = 2\beta^{-1}\beta = 2 \ne 0$ since $1 + 1 \ne 0$ 
            then
            \[
            H(\alpha v,w) = \alpha^2*\alpha^2 \ne \alpha *\alpha^2 = \alpha H(v,w)
            .\] 
            so $H$ is not billinear
        \item Let $v = 0, w = 1$ then
            \[
            2 = H(0 + 0, 1) = H(0,1) + H(0,1) = 2 + 2 = 4
            .\] 
            contradiction thus $H$ is not billinear
        \item 
            \[
            D(\begin{pmatrix} a \\ b \end{pmatrix} + \begin{pmatrix} c \\ d \end{pmatrix} , \begin{pmatrix} e \\ f \end{pmatrix} ) = (a+c)f-(b+d)e = af -be + cf -de = H(\begin{pmatrix} a \\ b \end{pmatrix} , \begin{pmatrix} e  \\ f \end{pmatrix} ) + H( \begin{pmatrix} c \\ d \end{pmatrix} , \begin{pmatrix} e \\ f \end{pmatrix} )
            .\] 
            also
            \[
            D( \begin{pmatrix} a \\ b \end{pmatrix} , \begin{pmatrix} c \\ d \end{pmatrix} ) = ad-bc = -(bc - ad) = -H(\begin{pmatrix} b \\ c \end{pmatrix} , \begin{pmatrix} a \\ d \end{pmatrix} )
            .\] 
            so D is also linear in the second argument
        \item 
            \[
            \langle \alpha v + u, w \rangle = \alpha \langle v, w \rangle + \langle u, w \rangle
            .\] 
            and since $F = \mathbb{R}$
            \[
            \langle v, w \rangle = \langle w ,v \rangle
            .\] 
            so $H$ is billinear
        \item 
            No consider
            \[
            \langle v, \alpha w \rangle = \overline{\langle \alpha w, v \rangle} = \overline{\alpha}\langle v, w \rangle
            .\] 
            so $H$ is conjugate linear in the second element but not linear
    \end{enumerate}
    \section{Exercise 2}
    \emph{
        Assume $V$ is a vector space and $\mathbb{B}(V)$ is the set of bilinear forms on $V$.
        \begin{enumerate}[label = (\alph*)]
            \item Prove Theorem 6.31. That is prove that if $H_1,H_2 \in \mathbb{B}(V)$ and $\alpha \in k$ implies
                $H_1 + H_2 \in \mathbb{B}$ and $\alpha H_1 \in \mathbb{B}$ and that $ \mathbb{B}(V)$ is a vector space over
                $k$ with respect to these operations.
            \item Assume the dimension of $V$ is $n \in \mathbb{Z}^{\ge 0}$. Compute the dimension of $ \mathbb{B}(V)$
        \end{enumerate}
    }
    \[
        (H_1 + H_2)(av + w, z) = H_1(av + w, z) + H_2(av + w, z) = a(H_1+H_2)(v,z) + (H_1+H_2)(w,z)
    .\] 
    similarly
    \[
        (H_1+H_2)(v, az + w) = H_1(v, az + w) + H_2(v, az + w) = a(H_1+H_2)(v,z) + (H_1+H_2)(v,w)
    .\] 
    these operations are associative and commutative since the field is. and ther exists zero $0 : V \times V \rightarrow F$ such that $0(v,w) = 0$
    Overall this is a vector space by inspection
    Additionally by the bijection between $  \mathbb{B}(V)$ and the set of all $\dim(V) \times \dim(V)$ matrices and considering the standard basis for matrices
    we have that $\dim( \mathbb{B}(V)) = \dim(V)^2$

    \section{Exercise 3}o
    \emph{
        Let $V$ be a vector space over a field $k$ and let $H$ denote a symmetric bilinear form on $V$.
        Prove if we define the function $K: V  \rightarrow k$ by the formula $K(v) = H(v,v)$ 
        \[
        H(v,w) = \frac{1}{2}(K(v + w) - K(v) -K(w))
        .\] 
        for all $v,w \in V$
    }
    Expanding the equation we get
    \[
    \frac{1}{2}(K(v+w) -K(v) -K(w)) = \frac{1}{2}(H(v + w, v+ w) - H(v,v) -H(w,w))
    .\] 
    \[
    = \frac{1}{2}(H(v,v) -H(v,v) + H(w,w) - H(w,w) + H(v,w) + H(w,v)) 
    \]
    \[
    = \frac{1}{2}(H(w,v) + H(v,w))  = \frac{1}{2}(2H(v,w)) = H(v,w)
    .\] 
    since
    \[
    H(v + w, v + w) = H(v,v +w ) + H(w,v+w) = H(v,v) + H(v,w) + H(w,v) + H(w,w)
    .\] 
    and H is symmetric
    \section{Exercise 4}
    \emph{
        Assume $T$ is a linear operator on a fdrips $V$ and define $H : V \times V \rightarrow \mathbb{R}$ by the formula
        $H(v,w) = \langle v, Tw \rangle$ for all $v,w \in V$
        \begin{enumerate}[label = (\alph*)]
           \item Prove that $H$ is a bilinear form.
           \item Prove that $H$ is symmetric iff $T$ is self adjoint
        \end{enumerate}
    }
    \begin{enumerate}[label = (\alph*)]
        \item 
            Linearity of inner product shows that H is linear in the first variable. In the second variable since V is real
            the function is a composition of linear functions and thus linear. so H is linear in both variables.
        \item If $T$ is self adjoint then
            \[
            H(v,w) = \langle v, Tw \rangle = \langle Tv, w \rangle = \langle w, Tv \rangle  = H(w,v)
            .\] 
            however if $T$ is not self adjoint there exist $v \in V$ such that $Tv \ne T^{*}v$ and
            similarly if $H$ is symmetric then for any $v,w \in V$
             \[
            \langle v, Tw \rangle = \langle w, Tv \rangle = \langle Tv, w \rangle
            .\] 
            so $T^{*} = T$
    \end{enumerate}
    \section{Exercise 5}
    \emph{
        Prove that if $V$ is a finite dimensional real inner product space and $H$ is a
        bilinear form on $V$, then there exists a unique linear operator $T: V \rightarrow V$ such that
        $H(v,w) = \langle v, Tw \rangle$ for all $v,w \in V$
    }\\
    pick an orthonormal basis $\mathcal{B} = \{v_1,v_2...,v_n\}$ for $V$ and let $A$ be the matrix representation of $H$ for
    this basis. Let $T : V \rightarrow V$ be the linear transformation for which $[T(v)]_B = A[v]_B$
    Let $L : V \times V \rightarrow \mathbb{R}$ defined by  $L(v,w) = \langle v, Tw \rangle$.
    By bilinearity it suffices to show that the two functions agree on any pair of basis vectors. Indeed
    \[
        H(v_i,v_j) = A_{ij}
    .\] 
    and
    \[
        \langle v_i, T v_j \rangle = \langle v_i, \sum_{k=1}^{n}A_{kj}v_k \rangle = \sum_{k=1}^{n}A_{kj}\langle v_i, v_k \rangle = A_{ij}
    .\] 
    so the functions agree on a basis and are the same.

    \section{Exercise 6}
    \emph{
        Assume $k$ is a field such that, for some positive integer $m$, $\sum_{i=1}^{m}1 = 1 + 1 + ... + 1 =0$. Prove the
        smallest positive integer $p$ for which $\sum_{i=1}^{p}1 = 0$ is prime.
    }
    assume $p$ is the smallest integer such that $\sum_{i=1}^{p}1 = 0$. Assume for contradiction that $p$ is not prime
    which means that $p = qr$ for some $q,r < p \in \mathbb{N}$. In particular $\sum_{i=1}^{q}1 \ne 0$ and $\sum_{i=1}^{r}1 \ne 0$ 
    so we can let $r = \sum_{i=1}^{r}1$ and $q = \sum_{i=1}^{q}1$
    \[
    qr = 0
    .\] 
    but since $k$ is a field, there exists $q^{-1}$ such that $q^{-1}q = 1$ so
    \[
    q^{-1}qr = q^{-1}0 \iff r = 0
    .\] 
    which is a contradiction thus $p$ cannot be written as the product of two smaller integers.

 \end{document}
