\documentclass{amsart}
\usepackage{amsfonts} % For math fonts
\usepackage{amsmath, amssymb, amsthm}
\usepackage{float}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{listings} % For custom coding font
\usepackage{xcolor}


\setlist[enumerate,1]{label=\arabic*.}
\setlist[enumerate,2]{label=\alph*.,itemindent=2em}
\setlist{topsep=0pt, leftmargin=*, labelsep=1em}

\title{HW3 CS 180}
\author{Asher Christian 006-150-286}
\date{ 30.01.25}

\begin{document}
\maketitle


\section{Exercise 1}
\emph{
    Given an unsorted integer array, find all pairs with a given difference k in it without using any extra space.
}
In particular this problem specifies that the program must use only $O(1)$ space. The goal time complexity is $O(n\log n)$

I propose the following algorithm that I will later justify
{\small
    \begin{itemize}
        \item \texttt{set k to be abs(k)}
        \item \texttt{use heap sort to sort the array in place in ascending order}
        \item \texttt{initialize two pointers both pointing to the first element one named first and one named second}
        \item \texttt{while the pointers are not pointing to the last element}
            \begin{itemize}
                \item \texttt{compute the difference between the elements pointed at by the pointer}
                \item \texttt{if the difference is equal to k output the values pointed at by both pointers in a pair and advance the second pointer and first pointer until they are both
                    pointing at new elements}
                \item \texttt{If the difference is greater than k advance the first pointer until it is pointing at a new element}
                \item \texttt{If the difference is less than k advance the second pointer until it is pointing at a new element}
                \item \texttt{if it any point the second pointer must advance but is incapable by the size of n, end the algorithm}
            \end{itemize}
    \end{itemize}
}
I will now prove the correctness of this algorithm assuming the correctness of the heap sort which I will later analyze.
Given the sorted array first note that if $k < 0$ then any pair with difference $k$ is also a pair with difference $-k$ in the other order
so it suffices to check those pairs with $k \ge 0$. Then since $k \ge 0$ all pairs in this sorted array will have the smaller element before the larger element.
Every pair outputed by my algorithm is valid as is verified by the difference calculation. Assume for contradiction
that there is a pair $(a,b)$ in the array such that $b-a = abs(k)$ and  it is not outputted by the algorithm. Consider the first time that
the first pointer points at a, there are three cases in which this could happen. First a is the initial element in which case the second pointer is also pointing to a.
the second case is if the algorithm previously found a pair with difference k and advanced both the first and second pointers to new elements. In this case let  $(c,d)$ be the 
previous pair then $c < a < d < b$ by the ordering and so the element pointed to by the second pointer is no greater than b. In the third case the difference was too large with some $c < a$ and so
the pointer was advanced to $a$. In this case the second pointer is also pointing to a value less than or equal to b for if it were not then it was pointing to an element larger than b and when it was pointing to b the difference between b and c
was too small and so the algorithm would have advanced the first pointer and kept the second poitner at b. Thus there is always a state in which a is pointed to by the first pointer
and the second pointer is poinging to a value less than or equal to $b$. If it is pointing to b it outputs (a,b) and we are done.
If it points to an element less than $b$, then the difference is less than k and so the second pointer advances. This happens repeatedly until
after a finite amount of steps the second pointer points to $b$ in which case the pair is outputted and we are done. Thus (a,b) is outputted and we are done. Note that
a must be visited by the first pointer since the first pointer visits every element. Note that the case where the algorithm terminates before examining every element, every
pair with largest element being the largest element of the array has been checked and so no more pairs exist.\\

Heapsort is as follows using array indexing in place of actual node storage of the heap.
{\small
    \begin{itemize}
        \item \texttt{Convert the array into a max heap}
            \begin{itemize}
                \item \texttt{For each item in the array}
                    \begin{itemize}
                        \item \texttt{while the item's parent node is smaller than it}
                            \begin{itemize}
                                \item \texttt{swap node with parent node}
                            \end{itemize}
                    \end{itemize}
            \end{itemize}
        \item \texttt{Pop off the maximum element and switch it for the last heap element to place it in final list}
            \begin{itemize}
                \item \texttt{Swap the first element of array with last element in heap}
                \item \texttt{While swapped element is not larger than both children}
                    \begin{itemize}
                        \item \texttt{swap with larger child}
                    \end{itemize}
            \end{itemize}
    \end{itemize}
}
We have covererd heaps in class so it is known that heapify works. In particular each time we add an element we add it to the bottom of the heap and then
heapify up to place it in a valid position. When the sorting stage happens we guarantee that at each step the largest element in the array not yet placed
is put at the end thus justifying a valid ordering. This algorithm takes $O(n\log n)$ time since each insertion or deletion takes $O(\log n)$ and $O(n)$ such
actions are performed.
The total running time of the algorithm is then $O(n \log n)$ dominated by the sorting. After sorting we do a linear time run through of the list as
each pointer visits every index $O(1)$ times since the indices only increase and at least one will increase at each comparison.

additionally the space complexity is $O(1)$ since heapsort is done in place, and every comparison and swap can be one with $O(1)$ extra variables
no data structure is introduced and no recursion creates memory usage.


\section{Exercise 6 P 108}
\emph{
    $G = (V,E)$,  $u \in V$ and bfs  $T$ = dfs  $T$ show that $G = T$
}
Suppose there exists some edge $e = (v,w) \in G$ and $e$ not in  $T$. Then
$v$ and $w$ must differ in layer by at most one level since $T$ is a bfs tree. In particular since 
$(v,w) \not\in T$  $v$ is not an ancestor of $w$ and $w$ is not an ancestor of $v$.
This contradicts the fact that $T$ is a dfs tree where each edge must connect 
elements such that one is the ancestor of the other in the tree structure. THus a contradiction
and so no such $e$ exists and $T = G$. 

\section{Exercise 4 P 190}
I propose the following greedy algorithm assuming $S$ and $S'$ are in array form or linked list form.
{\small
    \begin{itemize}
        \item \texttt{maintain an index of $S$ starting with the first element}
        \item \texttt{iterate through $S'$ }
            \begin{itemize}
                \item \texttt{using the index of $S$ continue forward until the first match of $S$ to the current
                    element of $S'$ }
                \item \texttt{if all of $S$ has been iterated over return false}
            \end{itemize}
        \item \texttt{if all of $S'$ has been iterated over successfully return true else return false}
    \end{itemize}
}
In essence this greedy algorithm scans $S$ matching elements in order of $S'$ as quickly as possible and ending after searching all of $S$ if
it hasnt already matched all of $S'$ in order. I propose that this algorithm works correctly.
Firstly if the algorithm returns true then it has matched every element of  $S'$ to an element of $S$ in strictly increasing order. This is
the specification of the problem and so it holds true.
Assume for contradiction that the algorithm returns false when it should have returned true then there exists some $\{s_1,s_2,...,s_n\} \subset S$ elements
such that their indexes are strictly increasing in $S$ that satisfy $S'$. Consider the algorithm upon finding each of these elements inductively. Upon finding the first element
it matches to the first element of $S'$ so it matches and continues. Inductively, every prior element has not been found before since it comes at an index strictly greater than that of the prior elements
and each element of this sequence comes directly after the previous element in $S'$ so when the algorithm reaches this element it would process it. Thus the algorithm would have processed every element in this list
and thus would have returned true which is a contradiction and so the algorithm is always correct.
This algorithm runs in $O(n+m)$ time because it checkes each element of $S$ and of $S'$ $O(1)$ times.
\section{Exercise 12 P 193}
I first claim that that claim:
\emph{
    There exists a valid schedule if and only if each stream $i$ satisfies $b_i \le rt_i$
}\\
is false.
Consider the $n=2$ streams with
\[
    (b_1,t_1) = (6000,1) \;\;\;\; (b_2,t_2) = (1000,1)
.\] 
and $r = 5000$
Then $b_1 = 6000  > 5000 * 1 = rt_1$ but the streaming order $2,1$ is valid because
\begin{align*}
    t &= 1: 1000 < 5000 * 1\\
    t &= 2: 7000 < 5000 * 2
\end{align*}
I propose the following algorithm
{\small
    \begin{itemize}
        \item \texttt{Sort the streams in order of increasing $\frac{b_i}{t_i}$}
        \item \texttt{iterate through the sorted array keeping track of the sum of bits $B$}
            \begin{itemize}
                \item \texttt{at each element of the array add $b_it_i$ to  $B$ and compare $B$ to $r\sum_{n=0}^{i}t_i$ }
                \item \texttt{If $B$ is greater than this product return false}
            \end{itemize}
    \end{itemize}
}
I first claim that when the algorithm returns true that there is a ordering that works.
Indeed By the loop to check for bits if at each ending time step (ending meaning one stream has ended)
the sum of bits is lower than the required maximum bits to be sent in that time interval. Assume for contradiction that
at some point during on of the streams the bits exceed the limit for that time. If that were the case pick the stream that the
overflow occurs in, Since the sum was below the required before the stream started the bit rate of the stream $\frac{b_i}{t_i}$ must have been greater 
than $r$. In this case by the end of the stream the total bits would have only continued to exceed the maximum and thus at the end of the stream it could be checked and determined
that the bit limit was exceeded. Thus if every endpoint is ok, every other point is also ok.
If the program instead returns false, assume for contradiction that there is a possible ordering
$S' = (s_0',s_1',....,s_n') \ne $  the sroted array in my algorithm.
I propose that at each time step in this ordering the amount of bits sent is at least as many as my sorted array.
Indeed consider the first time that the proposed ordering differs from mine.
Let $j$ be the index of $S'$ that this occurs and let $S$ by my ordering and $B$ the total bits that both of our orderings
have sent up until that point. Then at the next time step the total amount of bits sent by my algorithm is $B + \frac{s_j}{t_j}$
compared to $B  + \frac{s_j'}{t_j'}$ by the sorting of my list, my sum must be less or equal. Inductively at every time step my algorith must have less than or equal bits
sent out because the rates of bit addition is minimal by my sorting. Thus at the point where my ordering fails, the other proposed ordering must fail a contradiction and if my algorithm returns
false then there truly is not possible ordering.\\
My algorithm runs in $O(n\log(n))$ time. It runs a  $O(n\log(n))$ sort at the beginning of the algorithm once
It then loops through the array performing an $O(1)$ operation at each point for a total of $O(n)$ time. Thus the total is the sum which 
is  $O(n\log(n))$

\section{Exercise 3 P 189}
Let $S = \{s_1,s_2,...,s_n\}$ be the ordering as described by the greedy algorithm wtih each
\[
    s_i = \{x_{i,1},x_{i,2},...,x_{i,m}\}
.\] 
with each $x_i$ being a package.
and let $S' = \{s_1',...,s_k'\}$  be the alternative packaging scheme.
Assume for contradiction that $k < n$. Consider the first element of $s_1$ and $s_1'$. They must contain the same element
because $ x_{1,1}$ must be in both. in particular $1 \le 1$. for each extra package if it fits it will go into the same truck in $S$ but 
may or may not go into the truck in $S'$ so since packages start in less than or equal trucks, at each step the packages also go into trucks of index less than or equal to those in the newly proposed ordering.
Inductively this holds for every package so the last package must go into a truck less than or equal in index to the final truck of the new ordering which is a contradiction since $S'$ uses fewer trucks. So by contradiction
$S$ is optimal.


\section{Exercise 6 P 191}
I propose the following algorithm
{\small
    \begin{itemize}
        \item \texttt{Sort the players in terms of decreasing time to do the combined bike and run}
        \item \texttt{pick the players in order for longest to shortest time to bike and run}
    \end{itemize}
}
I will prove the optimality of my solution by showing that is is better than any other solution.
Consider any solution with two competitors $x_i,x_{i+1}$ such that $x_{i,r} < x_{i+1,r}$ (the time to run and bike for  $x_i$ is less
than that of $x_{i+1}$) and consider swaping the two comeptitors. Every competitor before  $x_i$ and after $x_{i+1}$ will start at the same time
and thus end at the same time. \\
in the original sorting $x_{i+1}$ would have finished after $x_i$ since it starts running abd biking after $x_i$ and takes longer to do both.
It suffices to show that in the swapped sorting both $x_i$ and $x_{i+1}$ finish faster than $x_{i+1}$ in the original sorting.\\
Indeed since $x_{i+1}$ starts earlier than it did in the original sorting it will finish earlier\\
additionally $x_{i}$ will start biking at the same time $x_{i+1}$ would start biking in the original ordering  and since
it is faster at biking and running it will finish faster. Thus swapping two competitors so as to comply with my proposed ordering can only increase
the optimality of a solution and thus starting with any solution executing multiple swaps to get to my ordering will only decrease total running time and so my ordering is optimal.


\section{Exercise 6 From Handout}
{\small
    \begin{itemize}
        \item \texttt{Pass through the matrix one time populating a weighted graph $G$  with a node for each orange}
        \item \texttt{add an edge for each adjacency relation with weight one and label all roten oranges with distance 0}
        \item \texttt{Keep track of all visited (rotten) oranges and the minimum distance to them and other nodes in a priority queue}
        \item \texttt{Run Dijkstra's algorithm on this graph until all oranges have been found}
        \item \texttt{If all oranges have a path to a rotten orange return the node with the largest value (distance) if not return that it is impossible
            to rot every orange}
    \end{itemize}
}
This algorithm works as specificed because every possible way a orange can turn rotten is contained in the edges of the graph including the time it owuld take for the rotting to happen
Additionally, by nature of Dijkstra's algorithm it is guaranteed to find the shortest path since all edges have positive weight.
\end{document}
